<!DOCTYPE html>
<html lang="en">

<!-- [Headers] -->

<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-8M8D0SS9T6"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-8M8D0SS9T6');
    </script>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@100;300;400;500;700;900&display=swap"
        rel="stylesheet">

    <title>HTLiang>Project>AutoGEM</title>

    <!-- Website Icon -->
    <link rel="shortcut icon" href="../assets/images//logo.ico" />
    <link rel="bookmark" href="../assets/images//logo.ico" />


    <!-- Bootstrap core CSS -->
    <link href="../vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">


    <!-- Additional CSS Files -->
    <link rel="stylesheet" href="../assets/css/fontawesome.css">
    <link rel="stylesheet" href="../assets/css/templatemo-572-designer.css">
    <link rel="stylesheet" href="../assets/css/owl.css">
    <link rel="stylesheet" href="../assets/css/animate.css">
    <link rel="stylesheet" href="https://unpkg.com/swiper@7/swiper-bundle.min.css" />

</head>

<body>

    <div class="loader">
        <svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
            x="0px" y="0px" width="34px" height="40px" viewBox="0 0 24 30" style="enable-background:new 0 0 50 50;"
            xml:space="preserve">
            <rect x="0" y="10" width="4" height="10" fill="#333" opacity="0.2">
                <animate attributeName="opacity" attributeType="XML" values="0.2; 1; .2" begin="0s" dur="0.8s"
                    repeatCount="indefinite" />
                <animate attributeName="height" attributeType="XML" values="10; 20; 10" begin="0s" dur="0.8s"
                    repeatCount="indefinite" />
                <animate attributeName="y" attributeType="XML" values="10; 5; 10" begin="0s" dur="0.8s"
                    repeatCount="indefinite" />
            </rect>
            <rect x="8" y="10" width="4" height="10" fill="#333" opacity="0.2">
                <animate attributeName="opacity" attributeType="XML" values="0.2; 1; .2" begin="0.15s" dur="0.8s"
                    repeatCount="indefinite" />
                <animate attributeName="height" attributeType="XML" values="10; 20; 10" begin="0.15s" dur="0.8s"
                    repeatCount="indefinite" />
                <animate attributeName="y" attributeType="XML" values="10; 5; 10" begin="0.15s" dur="0.8s"
                    repeatCount="indefinite" />
            </rect>
            <rect x="16" y="10" width="4" height="10" fill="#333" opacity="0.2">
                <animate attributeName="opacity" attributeType="XML" values="0.2; 1; .2" begin="0.3s" dur="0.8s"
                    repeatCount="indefinite" />
                <animate attributeName="height" attributeType="XML" values="10; 20; 10" begin="0.3s" dur="0.8s"
                    repeatCount="indefinite" />
                <animate attributeName="y" attributeType="XML" values="10; 5; 10" begin="0.3s" dur="0.8s"
                    repeatCount="indefinite" />
            </rect>
        </svg>
    </div>

    <header id="#top">
        <nav class="main-navigation navbar navbar-expand-lg navbar-light">
            <div class="container">
                <a class="navbar-brand" href="../"><img src="../assets/images/logo_removeBG.png" alt=""></a>
                <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav"
                    aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="navbar-toggler-icon"></span>
                </button>
                <div class="collapse navbar-collapse" id="navbarNav">
                    <ul class="navbar-nav">
                        <li class="nav-item">
                            <a class="nav-link" href="../">Home</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="../about">About Me</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link active" href="../works">Recent Works</a>
                        </li>
                        <!-- <li class="nav-item">
                            <a class="nav-link" href="../blog" target="_blank">Technical Blog</a>
                        </li> -->
                        <li class="nav-item">
                            <a class="nav-link" href="../contact">Contact Me</a>
                        </li>
                    </ul>
                </div>
            </div>
        </nav>
    </header>
    <!-- [End of Header ]-->

    <div class="page-banner-intro change-name">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 offset-lg-2">
                    <div class="header-text">
                        <h2>
                            <svg xmlns="http://www.w3.org/2000/svg" width="48" height="48" fill="currentColor"
                                class="bi bi-joystick" viewBox="0 0 16 16">
                                <path
                                    d="M10 2a2 2 0 0 1-1.5 1.937v5.087c.863.083 1.5.377 1.5.726 0 .414-.895.75-2 .75s-2-.336-2-.75c0-.35.637-.643 1.5-.726V3.937A2 2 0 1 1 10 2" />
                                <path
                                    d="M0 9.665v1.717a1 1 0 0 0 .553.894l6.553 3.277a2 2 0 0 0 1.788 0l6.553-3.277a1 1 0 0 0 .553-.894V9.665c0-.1-.06-.19-.152-.23L9.5 6.715v.993l5.227 2.178a.125.125 0 0 1 .001.23l-5.94 2.546a2 2 0 0 1-1.576 0l-5.94-2.546a.125.125 0 0 1 .001-.23L6.5 7.708l-.013-.988L.152 9.435a.25.25 0 0 0-.152.23z" />
                            </svg>
                            <em class="project">Works</em> & <em class="project">Side</em> Project
                        </h2>
                    </div>
                </div>
            </div>
        </div>
    </div>


    <section class="explore-item">
        <div class="container expanded">
            <div class="row">
                <div class="col-lg-8 offset-lg-2">
                    <div class="section-heading">
                        <h3><em>Auto</em>nomous Driving System for <em>GEM</em>e2 Vehicle</h3>
                        <h4>
                            # Keywords :
                            <span class="badge work-type-badge border">Robotics</span>
                            <span class="badge work-type-badge border">ROS</span>
                            <span class="badge work-type-badge border">Lane Following</span>
                            <span class="badge work-type-badge border">YOLO</span>
                            <span class="badge work-type-badge border">Vision-Based</span>
                        </h4>
                    </div>
                    <div class="main-image">
                        <img src="../assets/images/works/projects/AutoGEM/AutoGEM_Overview.jpg" alt="GEMe2">
                    </div>
                </div>
                <!-- <div class="col-lg-6">
                    <img src="assets/images/explore-item-02.jpg" alt="">
                </div>
                <div class="col-lg-6">
                    <img src="assets/images/explore-item-03.jpg" alt="">
                </div> -->
                <div class="col-lg-8 offset-lg-2">
                    <div class="article-content">
                        <p>
                            This project is the culmination of our work in the "ECE484: Principles of Safe Autonomy"
                            course at UIUC, undertaken by a team of four members.
                            The primary objective is to design a purely vision-based autonomous navigation system
                            capable of real-time lane following
                            while ensuring a smooth and reliable driving experience across various real-world scenarios.
                            The system is specifically designed to handle three critical situations: stop sign
                            detection, pedestrian detection, and navigating through road work zones.
                        </p>
                        <h4>Introduction</h4>
                        <p>
                            Imagine sitting in a vehicle that effortlessly takes you anywhere without the need for
                            manual operation, autonomous vehicles have the potential to turn this vision into reality.
                            A key component of such systems is a robust navigation system capable of reliable lane
                            following.
                            <br><br>
                            In this project, we focus on developing a purely vision-based navigation system, aiming to
                            eliminate dependence on costly sensors like LiDAR, thereby making autonomous technology more
                            accessible and scalable.
                            Our system is designed to perform real-time lane following while seamlessly handling
                            critical scenarios such as stop sign detection, pedestrian avoidance, and navigating road
                            work zones, showcasing its potential to enhance safety and adaptability across diverse
                            driving environments.
                        </p>
                        <h4>Approaches</h4>
                        <p>
                        <h6>Hardware Architecture</h6>
                        The whole system is based on ROS Noetic. All the nodes are running on a companion computer
                        equipped on the rover.
                        <h6>&gt; GEMe2 Vehicle</h6>
                        <p>
                            The following figure 1. is the hardware architecture of the GEMe2 Vehicle:
                        </p>
                        <div class="col-sm-12">
                            <img src="../assets/images/works/projects/AutoGEM/GEMe2.png" alt="GEMe2">
                            <h5>Figure 1. Hardware architecture</h5>
                        </div>
                        <p>
                            "AStuff Spectra2 Computer" (with CPU - Intel Xeon E-2278G 3.40GHz x16" and two GPUs - NVIDIA
                            RTX A4000) is the companion computer of the vehicle which deals with different signals from
                            sensors.
                            Multiple sensors were equipped on the vehicle.
                            The primary sensor utilized in this project is the ZED2 stereo camera, mounted at the front
                            of the vehicle.
                            It delivers a high-resolution 1080p video stream, serving as the primary source of
                            information for the system’s vision-based navigation and environment analysis.
                            <br><br>
                            For more information about GEMe2, please visit:
                            <a href="https://publish.illinois.edu/robotics-autonomy-resources/gem-e2/" target="_blank"
                                class="inline-link">https://publish.illinois.edu/robotics-autonomy-resources/gem-e2/</a>
                        </p>
                        <p>
                        <h6>Software Architecture</h6>
                        <br>
                        <div class="col-sm-12">
                            <img src="../assets/images/works/projects/AutoGEM/SystemArchitecture.png"
                                alt="system architecture">
                            <h5>Figure 2. Software architecture of the system.</h5>
                        </div>
                        <p>
                            Figure 2 illustrates the overall software architecture of the system.
                            As mentioned previously, the whole project is based on pure vision. Thus, the ZED2 camera is
                            the only sensor we are using.
                            There are three core components in the system: lane detection, vehicle control, and event
                            handling in real-world scenarios.

                        </p>
                        <h6>&gt; 1.Lane Detection</h6>
                        <p>
                            The overall workflow for lane detection is depicted in Figure 3.
                        </p>
                        <br><br>
                        <div class="col-sm-12">
                            <img src="../assets/images/works/projects/AutoGEM/lane_detection_workflow.png"
                                alt="lane detection workflow">
                            <h5>Figure 3. Workflow of lane detection.</h5>
                        </div>
                        <p>
                            The process begins with capturing raw RGB images from the camera,
                            which are then preprocessed using various filters to remove irrelevant details and noise.
                            Next, the filtered image is transformed into a bird's-eye view
                            using perspective transformation, providing a clear and top-down perspective of the road.
                            Finally, lane information is extracted through a lane-fitting algorithm,
                            enabling precise detection and mapping of the lanes.
                        </p>
                        <h6>-&gt; Filters</h6>
                        <p>
                            For the filtering process, we employ a combination of three methods to accurately identify
                            the final lane area:
                            gradient filtering, color filtering, and YOLOPv2. The gradient filter utilizes Canny Edge
                            Detection,
                            which is preprocessed with Gaussian blur to reduce noise
                            and post-processed with morphological dilation to enhance lane thickness and continuity.
                            For color filtering, we use the HLS color space to isolate white lane markings
                            and apply Contrast Limited Adaptive Histogram Equalization (CLAHE) to address uneven
                            lighting conditions
                            and improve visibility. YOLOPv2, a multi-task deep learning network derived from YOLOP,
                            is adept at perceiving lanes and other road features.
                            However, its high sensitivity can result in detecting extraneous areas.
                            To counter this, we integrate the output of YOLOPv2 with the results of the gradient and
                            color filters,
                            ensuring a refined and accurate final lane detection.
                        </p>
                        <div class="col-sm-12">
                            <img src="../assets/images/works/projects/AutoGEM/combined_view.gif" alt="combined_view">
                            <h5>Figure 4. Results of the filters. <br>[Note] Top-left: YOLOPv2 / Top-right: Color filter
                                / Down-left: Final output / Down-right: Gradient filter.</h5>
                        </div>
                        <h6>-&gt; Perspective Transform</h6>
                        <p>
                            In this step, the image is transformed into a bird's-eye view,
                            providing a top-down perspective of the road.
                            This process involves identifying the locations of four key points in the original image,
                            which define the region of interest,
                            and mapping them to corresponding points in the bird's-eye view.
                            These four points are adjusted to form the corners of the transformed image,
                            ensuring an accurate geometric representation of the lanes on a 2D plane.
                        </p>
                        <h6>-&gt; Lane Fitting Function</h6>
                        <p>
                            In the previous step, we obtain binary bird’s-eye view images that distinguish lane pixels
                            from the background.
                            The image is then horizontally segmented into several layers,
                            and the lane centers are identified for each layer.
                            To achieve this, we employ a histogram-based method.
                            For each horizontal layer, we calculate the histogram of pixels in both the left and right
                            halves of the image.
                            The areas with the highest pixel density are considered the centroids of each lane.
                            Finally, the coordinates of these lane centers are fitted to a second-order polynomial,
                            providing a smooth and accurate representation of the lane boundaries.
                        </p>
                        <h6>&gt; 2.Controller</h6>
                        <p>
                            The controller section of the system comprises three key components to ensure precise lane
                            following:
                        </p>
                        <div class="row">
                            <h6>-&gt; Waypoint Generation</h6>
                            <div class="col-sm-6">
                                <p>
                                    The process begins with detecting the lane boundaries in the image. The lane's
                                    midline is
                                    then divided into four equal segments, generating five waypoints. The vehicle’s
                                    current
                                    position is determined by calculating the ratio between a pixel in the image and the
                                    corresponding real-world distance on the ground.
                                </p>
                                <h6>-&gt; Steering Control</h6>
                                <p>
                                    A Pure Pursuit controller is used to calculate the steering angle needed to follow
                                    the lane
                                    accurately. This controller identifies the steering angle required to reach a
                                    designated
                                    target waypoint, positioned ahead of the vehicle, ensuring smooth and precise lane
                                    following.
                                </p>
                                <h6>-&gt; Speed Control</h6>
                                <p>
                                    A PID (Proportional-Integral-Derivative) controller is implemented to manage the
                                    vehicle's
                                    speed. It adjusts the acceleration or deceleration necessary to maintain the desired
                                    speed,
                                    ensuring consistent and optimal performance.

                                    By combining these control mechanisms, the system achieves both accurate steering
                                    and
                                    precise speed regulation, enabling smooth, safe, and efficient lane following.
                                </p>
                            </div>
                            <div class="col-sm-6">
                                <img src="../assets/images/works/projects/AutoGEM/controller.png" alt="controller">
                            </div>
                        </div>
                        <h6>&gt; 3.Real-World Scenarios Detection</h6>
                        <p>
                            In this section, we focus on detecting and responding to critical real-world driving
                            scenarios using a cutting-edge object detection model called YOLO v8. YOLO v8, developed by
                            Ultralytics, is renowned for its speed, accuracy, and ease of use. It leverages pre-trained
                            models to quickly and efficiently identify objects within images or video streams.
                            <br><br>
                            Our system utilizes YOLO v8 to detect three key scenarios:
                            <br>
                            - [1] Stop Sign Detection: <br>
                            The model is trained to recognize stop signs in real-time. Upon
                            detecting a stop sign, the system triggers a braking mechanism to bring the vehicle to a
                            complete halt.
                            <br><br>
                            - [2] Pedestrian Avoidance: <br>The system can detect pedestrians in the vehicle's path.
                            When a
                            pedestrian is detected, the system activates an avoidance maneuver, such as steering around
                            the pedestrian or slowing down significantly.
                            <br><br>
                            - [3] Road Work Zone Navigation: <br>
                            The system can identify warning cones or other markers indicating
                            road work zones. Upon detection, the system adjusts the vehicle's path to safely navigate
                            through the work zone, potentially slowing down or changing lanes as necessary.
                            <br><br>
                            By integrating YOLO v8 into our autonomous navigation system, we can enhance its safety and
                            reliability by enabling it to proactively respond to challenging real-world driving
                            situations. This system demonstrates the power of advanced object detection models in
                            creating more robust and intelligent autonomous vehicles.
                        </p>
                        </p>
                        <h4>Results</h4>
                        <p>
                            In summary, this project successfully demonstrates the ability to achieve lane following on
                            a full track, both in Gazebo simulation and in the real world. The system is capable of
                             navigating the lane, detecting stop signs, and identifying pedestrians, with the
                            vehicle coming to a stop when necessary. After a brief pause, the vehicle resumes motion
                            once no additional obstacles are detected. Additionally, the system can intelligently plan
                            and adjust its path when encountering road work zones, ensuring safe navigation through such
                            areas. This project showcases the effectiveness of a vision-based autonomous driving system
                            in real-world scenarios.
                        
                        <h6>&gt; Quick Demo</h6>
                            <div class="col-sm-12">
                                <div class="embed-responsive embed-responsive-16by9">
                                    <iframe class="embed-responsive-item"
                                        src="https://www.youtube.com/embed/wbmVWwUvd00?si=Qci8nfHYQcEIdEbd" frameborder="0"
                                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                                        allowfullscreen>
                                    </iframe>
                                </div>
    
                            </div>
                        <br>
                        <h6>&gt; Full Presentation</h6>
                        <div class="col-sm-12">
                            <div class="embed-responsive embed-responsive-16by9">
                                <iframe class="embed-responsive-item"
                                    src="https://www.youtube.com/embed/D_9AkWnf20w?si=XFZ9cHqQDZcz3GVZ" frameborder="0"
                                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                                    allowfullscreen>
                                </iframe>
                            </div>

                        </div>
                        </p>
                        <h4>Project Code</h4>
                        <p>
                            &gt; For the whole project code, please visit: <a
                                href="https://github.com/htliang517/AutoGem" target="_blank"
                                class="inline-link">https://github.com/htliang517/AutoGem</a>
                        </p>
                    </div>
                </div>
                <div class="col-lg-12">
                    <div class="projects-pagination">
                        <div class="row">
                            <div class="col-lg-6">
                                <div class="left-pagination">
                                </div>
                            </div>
                            <div class="col-lg-6">
                                <div class="right-pagination">
                                    <div class="float-end left-content">
                                        <a href="../works">
                                            <h6>
                                                <u>Back to List of Works</u>
                                                <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24"
                                                    fill="currentColor" class="bi bi-box-arrow-in-right"
                                                    viewBox="0 0 16 16">
                                                    <path fill-rule="evenodd"
                                                        d="M6 3.5a.5.5 0 0 1 .5-.5h8a.5.5 0 0 1 .5.5v9a.5.5 0 0 1-.5.5h-8a.5.5 0 0 1-.5-.5v-2a.5.5 0 0 0-1 0v2A1.5 1.5 0 0 0 6.5 14h8a1.5 1.5 0 0 0 1.5-1.5v-9A1.5 1.5 0 0 0 14.5 2h-8A1.5 1.5 0 0 0 5 3.5v2a.5.5 0 0 0 1 0z" />
                                                    <path fill-rule="evenodd"
                                                        d="M11.854 8.354a.5.5 0 0 0 0-.708l-3-3a.5.5 0 1 0-.708.708L10.293 7.5H1.5a.5.5 0 0 0 0 1h8.793l-2.147 2.146a.5.5 0 0 0 .708.708l3-3z" />
                                                </svg>
                                            </h6>
                                        </a>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>


    <!--  [Footer] -->
    <section class="call-to-action">
        <div class="container">
            <div class="row">
                <div class="col-lg-8">
                    <h2><em>Want To Know More About Me ?</em></h2>
                </div>
                <div class="col-lg-4">
                    <div class="white-button">
                        <a href="contact">Contact Me Now</a>
                    </div>
                </div>
            </div>
        </div>
    </section>


    <footer>
        <div class="container">
            <div class="row">
                <div class="col-md-3">
                    <div class="about-widget">
                        <h4>&nbsp</h4>
                        <img src="../assets/images/logo_white_BG.png" alt="Ideas Comes From Curiosity!">
                    </div>
                </div>

                <div class="col-md-7">
                    <h4>About Me</h4>
                    <p>
                        Majoring in Autonomy and Robotics at University of Illinois Urbana-Champaign.
                        Recieved Bachelor degree in Bio-mechatronics Engineering at National Taiwan University.
                        Interseted in coding and building autonomus robots. Hobbies are photography and hiking.
                        Seeking for opportunities to utilize the acquired skill sets
                        to contribute to the robot or software development industry.
                    </p>
                </div>
                <div class="col-md-2">
                    <h4>Contact Me</h4>
                    <div class="follow-us">
                        <ul class="social-links">
                            <li>
                                <a href="mailto:htliang517@gmail.com" target="_blank">
                                    <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor"
                                        class="bi bi-envelope-fill" viewBox="0 0 16 16">
                                        <path
                                            d="M.05 3.555A2 2 0 0 1 2 2h12a2 2 0 0 1 1.95 1.555L8 8.414.05 3.555ZM0 4.697v7.104l5.803-3.558L0 4.697ZM6.761 8.83l-6.57 4.027A2 2 0 0 0 2 14h12a2 2 0 0 0 1.808-1.144l-6.57-4.027L8 9.586l-1.239-.757Zm3.436-.586L16 11.801V4.697l-5.803 3.546Z" />
                                    </svg>
                                    Email
                                </a>
                            </li>
                            <li>
                                <a href="https://www.linkedin.com/in/htliang517" target="_blank">
                                    <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor"
                                        class="bi bi-linkedin" viewBox="0 0 16 16">
                                        <path
                                            d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854V1.146zm4.943 12.248V6.169H2.542v7.225h2.401zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248-.822 0-1.359.54-1.359 1.248 0 .694.521 1.248 1.327 1.248h.016zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016a5.54 5.54 0 0 1 .016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225h2.4z" />
                                    </svg>
                                    Linkedin
                                </a>
                            </li>
                            <li>
                                <a href="https://github.com/htliang517" target="_blank">
                                    <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor"
                                        class="bi bi-github" viewBox="0 0 16 16">
                                        <path
                                            d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z" />
                                    </svg>
                                    Github
                                </a>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
            <div class="row">

            </div>

            <div class="col-lg-12">
                <div class="sub-footer">
                    <div class="row">
                        <div class="col-lg-6">
                            <p>Copyright © 2025. Liang, Hua-Ta (Eric). All Rights Reserved. </p>
                        </div>
                        <div class="col-lg-6">
                            <a href="#top" class="scroll-to-top">
                                Go to Top
                                <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor"
                                    class="bi bi-arrow-bar-up" viewBox="0 0 16 16">
                                    <path fill-rule="evenodd"
                                        d="M8 10a.5.5 0 0 0 .5-.5V3.707l2.146 2.147a.5.5 0 0 0 .708-.708l-3-3a.5.5 0 0 0-.708 0l-3 3a.5.5 0 1 0 .708.708L7.5 3.707V9.5a.5.5 0 0 0 .5.5zm-7 2.5a.5.5 0 0 1 .5-.5h13a.5.5 0 0 1 0 1h-13a.5.5 0 0 1-.5-.5z" />
                                </svg>
                            </a>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        </div>
    </footer>
    <!-- (End of Footer) -->

    <!-- Scripts -->
    <!-- Bootstrap core JavaScript -->
    <script src="../vendor/jquery/jquery.min.js"></script>
    <script src="../vendor/bootstrap/js/bootstrap.min.js"></script>

    <script src="../assets/js/isotope.min.js"></script>
    <script src="../assets/js/owl-carousel.js"></script>
    <script src="../assets/js/wow.js"></script>
    <script src="../assets/js/tabs.js"></script>
    <script src="../assets/js/popup.js"></script>
    <script src="../assets/js/custom.js"></script>
    <script>
        setTimeout(function () {
            $('.loader').fadeToggle();
        }, 750);
        $("a[href='#top']").click(function () {
            $("html, body").animate({ scrollTop: 0 }, "slow");
            return false;
        });
    </script>

</body>

</html>