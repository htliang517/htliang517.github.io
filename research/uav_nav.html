<!DOCTYPE html>
<html lang="en">

<!-- [Headers] -->

<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-8M8D0SS9T6"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-8M8D0SS9T6');
    </script>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@100;300;400;500;700;900&display=swap"
        rel="stylesheet">

    <title>HTLiang>Research>UAV_Nav</title>

    <!-- Website Icon -->
    <link rel="shortcut icon" href="../assets/images//logo.ico" />
    <link rel="bookmark" href="../assets/images//logo.ico" />


    <!-- Bootstrap core CSS -->
    <link href="../vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">


    <!-- Additional CSS Files -->
    <link rel="stylesheet" href="../assets/css/fontawesome.css">
    <link rel="stylesheet" href="../assets/css/templatemo-572-designer.css">
    <link rel="stylesheet" href="../assets/css/owl.css">
    <link rel="stylesheet" href="../assets/css/animate.css">
    <link rel="stylesheet" href="https://unpkg.com/swiper@7/swiper-bundle.min.css" />

</head>

<body>

    <div class="loader">
        <svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
            x="0px" y="0px" width="34px" height="40px" viewBox="0 0 24 30" style="enable-background:new 0 0 50 50;"
            xml:space="preserve">
            <rect x="0" y="10" width="4" height="10" fill="#333" opacity="0.2">
                <animate attributeName="opacity" attributeType="XML" values="0.2; 1; .2" begin="0s" dur="0.8s"
                    repeatCount="indefinite" />
                <animate attributeName="height" attributeType="XML" values="10; 20; 10" begin="0s" dur="0.8s"
                    repeatCount="indefinite" />
                <animate attributeName="y" attributeType="XML" values="10; 5; 10" begin="0s" dur="0.8s"
                    repeatCount="indefinite" />
            </rect>
            <rect x="8" y="10" width="4" height="10" fill="#333" opacity="0.2">
                <animate attributeName="opacity" attributeType="XML" values="0.2; 1; .2" begin="0.15s" dur="0.8s"
                    repeatCount="indefinite" />
                <animate attributeName="height" attributeType="XML" values="10; 20; 10" begin="0.15s" dur="0.8s"
                    repeatCount="indefinite" />
                <animate attributeName="y" attributeType="XML" values="10; 5; 10" begin="0.15s" dur="0.8s"
                    repeatCount="indefinite" />
            </rect>
            <rect x="16" y="10" width="4" height="10" fill="#333" opacity="0.2">
                <animate attributeName="opacity" attributeType="XML" values="0.2; 1; .2" begin="0.3s" dur="0.8s"
                    repeatCount="indefinite" />
                <animate attributeName="height" attributeType="XML" values="10; 20; 10" begin="0.3s" dur="0.8s"
                    repeatCount="indefinite" />
                <animate attributeName="y" attributeType="XML" values="10; 5; 10" begin="0.3s" dur="0.8s"
                    repeatCount="indefinite" />
            </rect>
        </svg>
    </div>

    <header id="#top">
        <nav class="main-navigation navbar navbar-expand-lg navbar-light">
            <div class="container">
                <a class="navbar-brand" href="../"><img src="../assets/images/logo_removeBG.png" alt=""></a>
                <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav"
                    aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="navbar-toggler-icon"></span>
                </button>
                <div class="collapse navbar-collapse" id="navbarNav">
                    <ul class="navbar-nav">
                        <li class="nav-item">
                            <a class="nav-link" href="../">Home</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="../about">About Me</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link active" href="../works">Recent Works</a>
                        </li>
                        <!-- <li class="nav-item">
                            <a class="nav-link" href="../blog" target="_blank">Technical Blog</a>
                        </li> -->
                        <li class="nav-item">
                            <a class="nav-link" href="../contact">Contact Me</a>
                        </li>
                    </ul>
                </div>
            </div>
        </nav>
    </header>
    <!-- [End of Header ]-->

    <div class="page-banner-intro change-name">
        <div class="container">
            <div class="row">
                <div class="col-lg-6 offset-lg-3">
                    <div class="header-text">
                        <h2>
                            <svg xmlns="http://www.w3.org/2000/svg" width="48" height="48" fill="currentColor"
                                class="bi bi-compass" viewBox="0 0 16 16">
                                <path
                                    d="M8 16.016a7.5 7.5 0 0 0 1.962-14.74A1 1 0 0 0 9 0H7a1 1 0 0 0-.962 1.276A7.5 7.5 0 0 0 8 16.016m6.5-7.5a6.5 6.5 0 1 1-13 0 6.5 6.5 0 0 1 13 0" />
                                <path d="m6.94 7.44 4.95-2.83-2.83 4.95-4.949 2.83 2.828-4.95z" />
                            </svg>
                            <em class="research">Research</em> Project
                        </h2>
                    </div>
                </div>
            </div>
        </div>
    </div>


    <section class="explore-item">
        <div class="container expanded">
            <div class="row">
                <div class="col-lg-8 offset-lg-2">
                    <div class="section-heading">
                        <h3><em>Autonomous Navigation Control</em> of Multi-Rotor Unmanned Aerial Vehicle in Greenhouse
                        </h3>
                        <h4>
                            # Keywords :
                            <span class="badge work-type-badge border">Robotics</span>
                            <span class="badge work-type-badge border">ROS</span>
                            <span class="badge work-type-badge border">Visual SLAM</span>
                            <span class="badge work-type-badge border">RTAB-Map</span>
                            <span class="badge work-type-badge border">YOLO</span>
                            <span class="badge work-type-badge border">Deep SORT</span>
                            <span class="badge work-type-badge border">PX4</span>
                        </h4>
                    </div>
                    <div class="main-image col-sm-8 offset-sm-2">
                        <img src="../assets/images/works/research/uav_nav/drone.jpg" alt="Uav Navigation">
                    </div>
                </div>
                <!-- <div class="col-lg-6">
                    <img src="assets/images/explore-item-02.jpg" alt="">
                </div>
                <div class="col-lg-6">
                    <img src="assets/images/explore-item-03.jpg" alt="">
                </div> -->
                <div class="col-lg-8 offset-lg-2">
                    <div class="article-content">
                        <p>
                            This research was my bachelor thesis conducted under Professor Lin,Ta-Te.
                            It had also received a fellowship for undergraduate research from the Ministry of Science
                            and Technology.
                            <br><br>
                            In recent years, the widespread use of unmanned aerial vehicles (UAVs) in various fields has
                            been hampered by challenges in indoor navigation due to satellite signal masking. This
                            research focuses on developing an indoor autonomous navigation system for UAVs, utilizing a
                            Visual SLAM algorithm instead of traditional Wi-Fi-based triangulation. Built on ROS Noetic
                            with Ubuntu 20.04, our system employs RTAB-Map and ROS move_base for navigation, along with
                            YOLOv4 and Deep SORT for flower detection and counting. By addressing the limitations of
                            traditional methods, we aim to facilitate UAV applications in greenhouse operations with
                            enhanced precision and reduced technical barriers.
                        </p>
                        <h4>Introduction</h4>
                        <p>
                            With the rapid progress in science and technology, unmanned aerial vehicles (UAVs) find
                            extensive applications across diverse sectors. In the mining industry, UAVs play a pivotal
                            role in tasks such as 3D mapping of mine environments, ore control, rock discontinuity
                            mapping, post-blast rock fragmentation measurements, and tailing stability monitoring.
                            Similarly, in agriculture, UAVs are commonly utilized for efficient pesticide spraying over
                            large areas. While modern UAVs rely on global positioning systems (GPS) for positioning and
                            route planning, challenges arise in indoor environments due to signal masking, leading to
                            localization deviations. Addressing this, the research focuses on developing an indoor
                            autonomous navigation system for UAVs, aiming to create a simulation system for automatic
                            mapping and route planning.
                        </p>
                        <h4>Approaches</h4>
                        <h6>> Overall System Archetecture</h6>
                        <div class="row col-sm-10 offset-sm-1">
                            <img src="../assets/images/works/research/uav_nav/SystemOverview.png" alt="">
                            <h5>Figure 1. Overall system archetecture</h5>
                        </div>
                        <p>
                            The UAV system we had designed was composed of three main components:
                            <br>
                            1. Companion Computer: We used Raspberry Pi 4 as our companion computer. 
                            A companion computer is used to reduce the computational load of the flight control unit.
                            <br>
                            2. Flight Control Unit(FCU)
                            The flight control unit is used to monitor and control the four rotors. The flight control board equipped on our UAV was
                            Pixhawk. Pixhawk is an open-sourced flight controller which contains built-in inertial measurement units (IMU).
                            <br>
                            3. Ground Control Station(GCS)
                            A ground control station(GCS) is typically a software application running on a ground-based computer that communicates
                            with the UAV through telemetry. It will monitor and display the real-time data and signals on the UAV. It can also be
                            used to control the UAV in flight by uploading new mission plan or commands.
                        </p>
                        <h6>> Navigation System</h6>
                        <p>
                            Traditional method of indoor navigation for UAVs is triangulation. 
                            This method estimates the position of UAV based on the Wi-Fi signal strengths transmitted from different Wi-Fi routers.
                            Thus, multiple Wi-Fi devices is needed. The reason for not using triangulation in this study is that 
                            this method requires multiple routers to be set up indoors 
                            which not only increases the trouble for farmers to use but also raise the cost of installation and maintenance in the future.
                            Therefore, compared with traditional methods of indoor navigation, we use Visual SLAM algorithm for UAV autonomous navigation in this research. 
                            The VSLAM system used in this research is RTAB-Map.
                            <br><br>
                            The whole navigation system can be roughly separated into three parts: mapping, localization and route planning. Both
                            mapping and localization would be done by RTAB-Map and route planning would be implemented by move_base. Move_base is a
                            ROS package that provides an implementation of an action that will let the robot attempt to reach a given goal in the
                            world with its mobile base.
                            
                            The map of the whole environment would be constructed by conducting a guidance flight at the first flight. RTAB-Map will
                            take the RGB-D images, IMU data from the flight control unit, and camera information as input to calculate the visual
                            odometry. It will then generate a 2D occupancy grid map and the TF (transform of the robot from /map to /odom). The two
                            data are then sent back to the flight controller in order to let the controller know the position of the UAV. These two
                            data would also be used by the move_base package in order to plan route to reach the target position.
                        </p>
                        <div class="row col-sm-12">
                            <img src="../assets/images/works/research/uav_nav/SystemBlockDiagram.png" alt="">
                            <h5>Figure 2. Block diagram of the whole system</h5>
                        </div>
                        <h6>> Application: Flower Counting System</h6>
                        <p>
                            In addition, deep learning was also applied to this research in order to provide a simple application with this system. 
                            Our training model was to identify and calculate the amount of the flowers of eustoma farms. 
                            Flower growers are often concerned about how many flowers grown in the greenhouse since this is highly related to their income. 
                            Thus, a flower counting system is implemented using YOLOv4 and Deep Sort. 
                            Figure 3. shows the system archetecture of the flower counting system.
                        </p>
                        <div class="row col-sm-12">
                            <img src="../assets/images/works/research/uav_nav/YOLOv4withDeepsort.png" alt="">
                            <h5>Figure 3. Flower counting system archetecture with YOLOv4 and Deep Sort</h5>
                        </div>

                        <h4>Results</h4>
                        <p>
                        </p>
                        <p>
                            The UAV model we were using in the simulation is provided by PX4-Autopilot on GitHub and the greenhouse model was
                            designed referring to the Eustoma farm situated in Changhua County. Once the UAV is armed, we can control our UAV
                            through Rviz, a 3D visualization tool in ROS. We can add waypoints to the map by clicking on the control panel (Figure
                            12). The UAV will then navigate to the designated location if the goal is reachable. This action is done by adding goals
                            to move_base service and the service will complete route planning. While moving the UAV around, RTAB-Map is also
                            publishing the location and poses of the UAV and updating maps to provide sufficient navigation information to move_base
                            service. Figure 4. was the mapping result of the simulation environment. We had also tested our system on our UAVs in the greenhouse. 
                            Figure 5. was the mapping result of a single block of the actual eustoma farm.
                        </p>
                        <div class="row">
                            <div class="col-sm-7">
                                <img src="../assets/images/works/research/uav_nav/simulation.png" alt="">
                                <h5>Figure 4. Mapping result in simulation using Gazebo and Rviz</h5>
                            </div>
                            <div class="col-sm-4 offset-sm-1">
                                <img src="../assets/images/works/research/uav_nav/drone.jpg" alt="">
                                <h5>Figure 5. Mapping result in reality</h5>
                            </div>
                        </div>
                        <p>
                            Pictures of the flowers were taken from the camera equipped on the UAV. These pictures were then used for our model
                            training so that it could be used for flower detection in the future.
                            We collected 179 pictures taken from the greenhouse and approximately 20 to 80 flowers on average are in each picture.
                            After training from the collected images from the farm, our YOLO model can achieve F1 score 0.968, representing that the
                            model we had trained can identify the eustoma flowers accurately.
                            <br><br>
                            Figure 6 was our flower counting system combined with YOLOv4 and Deep SORT. We first recorded the video through the
                            Realsense camera equipped on the UAV and then this video was input into our flower detecting system. While detected a
                            new flower in the frame, Deep SORT would then start figuring the detected flower’s ID. If the flower was new detected in
                            the frame, Deep SORT would assign a new ID to it, otherwise the flower would obtain its original ID assigned while it
                            was first detected. We could then use this ID to count the flower amount of the whole video.
                        </p>
                        <div class="row col-sm-10 offset-sm-1">
                            <img src="../assets/images/works/research/uav_nav/flower_detection.png" alt="">
                            <h5>Figure 6. Flower counting system with YOLOv4 and Deep SORT</h5>
                        </div>
                        <h4>Publication</h4>
                        <p>
                            Bachelor Thesis <br>
                            <a href="https://drive.google.com/file/d/12jyPmkv3QKi3j0LRHbomRwebeSe-pRvo/view?usp=sharing" class="inline-link"> 
                                https://drive.google.com/file/d/12jyPmkv3QKi3j0LRHbomRwebeSe-pRvo/view?usp=sharing </a>
                        </p>
                    </div>
                </div>
                <div class="col-lg-12">
                    <div class="projects-pagination">
                        <div class="row">
                            <div class="col-lg-6">
                                <div class="left-pagination">
                                </div>
                            </div>
                            <div class="col-lg-6">
                                <div class="right-pagination">
                                    <div class="float-end left-content">
                                        <a href="../works">
                                            <h6>
                                                <u>Back to List of Works</u>
                                                <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24"
                                                    fill="currentColor" class="bi bi-box-arrow-in-right"
                                                    viewBox="0 0 16 16">
                                                    <path fill-rule="evenodd"
                                                        d="M6 3.5a.5.5 0 0 1 .5-.5h8a.5.5 0 0 1 .5.5v9a.5.5 0 0 1-.5.5h-8a.5.5 0 0 1-.5-.5v-2a.5.5 0 0 0-1 0v2A1.5 1.5 0 0 0 6.5 14h8a1.5 1.5 0 0 0 1.5-1.5v-9A1.5 1.5 0 0 0 14.5 2h-8A1.5 1.5 0 0 0 5 3.5v2a.5.5 0 0 0 1 0z" />
                                                    <path fill-rule="evenodd"
                                                        d="M11.854 8.354a.5.5 0 0 0 0-.708l-3-3a.5.5 0 1 0-.708.708L10.293 7.5H1.5a.5.5 0 0 0 0 1h8.793l-2.147 2.146a.5.5 0 0 0 .708.708l3-3z" />
                                                </svg>
                                            </h6>
                                        </a>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>


    <!--  [Footer] -->
    <section class="call-to-action">
        <div class="container">
            <div class="row">
                <div class="col-lg-8">
                    <h2><em>Want To Know More About Me ?</em></h2>
                </div>
                <div class="col-lg-4">
                    <div class="white-button">
                        <a href="contact">Contact Me Now</a>
                    </div>
                </div>
            </div>
        </div>
    </section>


    <footer>
        <div class="container">
            <div class="row">
                <div class="col-md-3">
                    <div class="about-widget">
                        <h4>&nbsp</h4>
                        <img src="../assets/images/logo_white_BG.png" alt="Ideas Comes From Curiosity!">
                    </div>
                </div>

                <div class="col-md-7">
                    <h4>About Me</h4>
                    <p>
                        Majoring in Autonomy and Robotics at University of Illinois Urbana-Champaign.
                        Recieved Bachelor degree in Bio-mechatronics Engineering at National Taiwan University.
                        Interseted in coding  and building autonomus robots. Hobbies are photography and hiking.
                        Seeking for opportunities to utilize the acquired skill sets 
                        to contribute to the robot or software development industry.
                    </p>
                </div>
                <div class="col-md-2">
                    <h4>Contact Me</h4>
                    <div class="follow-us">
                        <ul class="social-links">
                            <li>
                                <a href="mailto:htliang517@gmail.com" target="_blank">
                                    <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor"
                                        class="bi bi-envelope-fill" viewBox="0 0 16 16">
                                        <path
                                            d="M.05 3.555A2 2 0 0 1 2 2h12a2 2 0 0 1 1.95 1.555L8 8.414.05 3.555ZM0 4.697v7.104l5.803-3.558L0 4.697ZM6.761 8.83l-6.57 4.027A2 2 0 0 0 2 14h12a2 2 0 0 0 1.808-1.144l-6.57-4.027L8 9.586l-1.239-.757Zm3.436-.586L16 11.801V4.697l-5.803 3.546Z" />
                                    </svg>
                                    Email
                                </a>
                            </li>
                            <li>
                                <a href="https://www.linkedin.com/in/htliang517" target="_blank">
                                    <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor"
                                        class="bi bi-linkedin" viewBox="0 0 16 16">
                                        <path
                                            d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854V1.146zm4.943 12.248V6.169H2.542v7.225h2.401zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248-.822 0-1.359.54-1.359 1.248 0 .694.521 1.248 1.327 1.248h.016zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016a5.54 5.54 0 0 1 .016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225h2.4z" />
                                    </svg>
                                    Linkedin
                                </a>
                            </li>
                            <li>
                                <a href="https://github.com/htliang517" target="_blank">
                                    <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor"
                                        class="bi bi-github" viewBox="0 0 16 16">
                                        <path
                                            d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z" />
                                    </svg>
                                    Github
                                </a>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
            <div class="row">

            </div>

            <div class="col-lg-12">
                <div class="sub-footer">
                    <div class="row">
                        <div class="col-lg-6">
                            <p>Copyright © 2025. Liang, Hua-Ta (Eric). All Rights Reserved. </p>
                        </div>
                        <div class="col-lg-6">
                            <a href="#top" class="scroll-to-top">
                                Go to Top
                                <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor"
                                    class="bi bi-arrow-bar-up" viewBox="0 0 16 16">
                                    <path fill-rule="evenodd"
                                        d="M8 10a.5.5 0 0 0 .5-.5V3.707l2.146 2.147a.5.5 0 0 0 .708-.708l-3-3a.5.5 0 0 0-.708 0l-3 3a.5.5 0 1 0 .708.708L7.5 3.707V9.5a.5.5 0 0 0 .5.5zm-7 2.5a.5.5 0 0 1 .5-.5h13a.5.5 0 0 1 0 1h-13a.5.5 0 0 1-.5-.5z" />
                                </svg>
                            </a>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        </div>
    </footer>
    <!-- (End of Footer) -->

    <!-- Scripts -->
    <!-- Bootstrap core JavaScript -->
    <script src="../vendor/jquery/jquery.min.js"></script>
    <script src="../vendor/bootstrap/js/bootstrap.min.js"></script>

    <script src="../assets/js/isotope.min.js"></script>
    <script src="../assets/js/owl-carousel.js"></script>
    <script src="../assets/js/wow.js"></script>
    <script src="../assets/js/tabs.js"></script>
    <script src="../assets/js/popup.js"></script>
    <script src="../assets/js/custom.js"></script>
    <script>
        setTimeout(function () {
            $('.loader').fadeToggle();
        }, 750);
        $("a[href='#top']").click(function () {
            $("html, body").animate({ scrollTop: 0 }, "slow");
            return false;
        });
    </script>

</body>

</html>